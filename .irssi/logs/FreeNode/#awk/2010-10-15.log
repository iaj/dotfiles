--- Log opened Fri Oct 15 10:30:18 2010
10:30 --- Users 94 nicks [0 ops, 0 halfops, 0 voices, 94 normal]
10:31 --- Channel #awk was synced in 105 seconds
--- Log opened Fri Oct 15 13:49:18 2010
13:49 --- Users 100 nicks [0 ops, 0 halfops, 0 voices, 100 normal]
13:49 --- Server: [calvino.freenode.net] [freenode-info] if you're at a conference and other people are having trouble connecting, please mention it to staff: http://freenode.net/faq.shtml#gettinghelp
13:50  karthee: hi .. I am writing a log analyzer for my application using awk .. The first two columns give the time stamp in the format  2010-10-15 07:21:14 .. How do I pull all the lines in a specific date range.. Basically how do I compare dates in awk ?
13:50  karthee: hi .. I am writing a log analyzer for my application using awk .. The first two columns give the time stamp in the format  2010-10-15 07:21:14 .. How do I pull all the lines in a specific date range.. Basically how do I compare dates in awk ?
13:50 --- Channel #awk was synced in 109 seconds
13:55  pgas: standard awk knows nothing about dates
13:55  pgas: standard awk knows nothing about dates
13:56  pgas: but your date seems to be in a format that can be compared lexically so you should be able to use > to compare the date as strings
13:56  pgas: but your date seems to be in a format that can be compared lexically so you should be able to use > to compare the date as strings
14:03  \DSAFEW\: let me add that there is an awk function to call the system time/date
14:03  \DSAFEW\: let me add that there is an awk function to call the system time/date
14:14  geirha: If the lines are in order, you could do something like awk '/^2010-10-15 07:21/,/^2010-10-15 10:00/'
14:14  geirha: If the lines are in order, you could do something like awk '/^2010-10-15 07:21/,/^2010-10-15 10:00/'
14:14  geirha: s/order/sorted by timestamp/
14:14  geirha: s/order/sorted by timestamp/
14:17  pgas: \DSAFEW\: only in gnu awk 
14:17  pgas: \DSAFEW\: only in gnu awk 
14:17  karthee: i just came across  http://www.gnu.org/manual/gawk/html_node/Time-Functions.html   .. any ways to compare time by converting them to  epoc time or something
14:17  karthee: i just came across  http://www.gnu.org/manual/gawk/html_node/Time-Functions.html   .. any ways to compare time by converting them to  epoc time or something
14:17  karthee: ?
14:17  karthee: ?
14:19  \DSAFEW\: karthee, I don't think converting your logs to epoch and then filtering that is any more efficient than just filtering the date ranges in the first place
14:19  \DSAFEW\: karthee, I don't think converting your logs to epoch and then filtering that is any more efficient than just filtering the date ranges in the first place
14:20  \DSAFEW\: karthee, are all your logs in flat text files?
14:20  \DSAFEW\: karthee, are all your logs in flat text files?
14:21  karthee: \DSAFEW\: yes they are flat text files ..  so something like ..  awk '/^2010-10-15 07:21/,/^2010-10-15 10:00/' .. should do .. right ?
14:21  karthee: \DSAFEW\: yes they are flat text files ..  so something like ..  awk '/^2010-10-15 07:21/,/^2010-10-15 10:00/' .. should do .. right ?
14:22  \DSAFEW\: karthee, like geirha says, if they're ordered
14:22  \DSAFEW\: karthee, like geirha says, if they're ordered
14:22  karthee: \DSAFEW\: yes they are ordered .. That should work for me .. 
14:22  karthee: \DSAFEW\: yes they are ordered .. That should work for me .. 
14:22  \DSAFEW\: karthee, I'm not sure about a longer pattern to match them all out of order
14:22  \DSAFEW\: karthee, I'm not sure about a longer pattern to match them all out of order
14:23  \DSAFEW\: geirha thanks
14:23  \DSAFEW\: geirha thanks
14:24  karthee: \DSAFEW\:  geirha: me too . thanks ..
14:24  karthee: \DSAFEW\:  geirha: me too . thanks ..
14:24  \DSAFEW\: I think converting them to an array or something would be a PITA, unless someone has an easy way with gawk's date functions
14:24  \DSAFEW\: I think converting them to an array or something would be a PITA, unless someone has an easy way with gawk's date functions
14:24  \DSAFEW\: datestamps are fine as text for now though
14:24  \DSAFEW\: datestamps are fine as text for now though
14:25  pgas: karthee: since you can compare your dates as strings you can do:  awk '$1 " " $2 > "2010-10-15 07:21"' # to print all the line after 2010-10-15 07:21
14:25  pgas: karthee: since you can compare your dates as strings you can do:  awk '$1 " " $2 > "2010-10-15 07:21"' # to print all the line after 2010-10-15 07:21
14:26  karthee: \DSAFEW\:   im worried if logs were not there on the particular minute/ hour that we specify ..  let say i want logs from 9 to 10 ,    awk '/^2010-10-15 09:00/,/^2010-10-15 10:00/' .. May be the no logs on that time . right 
14:26  karthee: \DSAFEW\:   im worried if logs were not there on the particular minute/ hour that we specify ..  let say i want logs from 9 to 10 ,    awk '/^2010-10-15 09:00/,/^2010-10-15 10:00/' .. May be the no logs on that time . right 
14:27  karthee: pgas: ohh .. let me try that .. 
14:27  karthee: pgas: ohh .. let me try that .. 
14:28  karthee: pgas: Coooooooooooool .. Thanks 
14:28  karthee: pgas: Coooooooooooool .. Thanks 
14:43  karthee: pgas:  awk '$1 " " $2 > "2010-10-15 05:51"'  .. This gives ONLY the lines which are all having  2010-10-15 05:51  ..    
14:43  karthee: pgas:  awk '$1 " " $2 > "2010-10-15 05:51"'  .. This gives ONLY the lines which are all having  2010-10-15 05:51  ..    
14:43  karthee: :-D
14:43  karthee: :-D
14:46  pgas: 4# echo '2010-10-16 21:09' | awk '$1 " " $2 > "2010-10-15 05:51"'
14:46  pgas: 4# echo '2010-10-16 21:09' | awk '$1 " " $2 > "2010-10-15 05:51"'
14:46  shbot: pgas: 2010-10-16 21:09
14:46  shbot: pgas: 2010-10-16 21:09
14:46  pgas: works here
14:46  pgas: works here
14:47  pgas: karthee: maybe you have something that is not a space between $1 and $2?
14:47  pgas: karthee: maybe you have something that is not a space between $1 and $2?
14:48  karthee: pgas: let me copy and paste yours .. 
14:48  karthee: pgas: let me copy and paste yours .. 
14:58  stockholm: hi
14:58  stockholm: hi
14:59  stockholm: how do i get the macs of eth0 (and if exists of eth1) printet from ip link show ?
14:59  stockholm: how do i get the macs of eth0 (and if exists of eth1) printet from ip link show ?
15:02  stockholm: the point is that i need to switch lines after i found eth[0-9] on one line
15:02  stockholm: the point is that i need to switch lines after i found eth[0-9] on one line
15:02  stockholm: and operate on the next line
15:02  stockholm: and operate on the next line
15:05  pgas: awk '/eth[0-9]/{f=1} f && ...do the things on the next line'
15:05  pgas: awk '/eth[0-9]/{f=1} f && ...do the things on the next line'
15:05  pgas: awk '/eth[0-9]/{f=1} f && ...do the things on the next line;f=0}'
15:05  pgas: awk '/eth[0-9]/{f=1} f && ...do the things on the next line;f=0}'
16:18  stockholm: pgas: what syntax is there inbetween?
16:18  stockholm: pgas: what syntax is there inbetween?
16:18  stockholm: ip link show| awk '/eth[0-9]/{f=1} f && { print $2};f=0}'
16:18  stockholm: ip link show| awk '/eth[0-9]/{f=1} f && { print $2};f=0}'
16:18  stockholm: awk: /eth[0-9]/{f=1} f && { print $2};f=0}
16:18  stockholm: awk: /eth[0-9]/{f=1} f && { print $2};f=0}
16:18  stockholm: awk:                      ^ syntax error
16:18  stockholm: awk:                      ^ syntax error
16:18  stockholm: moment
16:18  stockholm: moment
16:19  stockholm: no, doesnt work either
16:19  stockholm: no, doesnt work either
16:20  stockholm: what is wrong with my {?
16:20  stockholm: what is wrong with my {?
16:21  pgas: the problem is the } after $2
16:21  pgas: the problem is the } after $2
16:22  pgas: and and you don't need &&
16:22  pgas: and and you don't need &&
16:22  stockholm: oh?
16:22  stockholm: oh?
16:22  pgas: ip link show| awk '/eth[0-9]/{f=1} f {print $2;f=0}'
16:22  pgas: ip link show| awk '/eth[0-9]/{f=1} f {print $2;f=0}'
--- Log closed Fri Oct 15 16:33:36 2010
--- Log closed Fri Oct 15 16:33:38 2010
--- Log opened Fri Oct 15 18:17:18 2010
18:17 --- Users 98 nicks [0 ops, 0 halfops, 0 voices, 98 normal]
18:18 --- Channel #awk was synced in 106 seconds
--- Log closed Sat Oct 16 11:43:50 2010
