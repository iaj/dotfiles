--- Log opened Thu Nov 04 08:21:56 2010
08:21 --- Users 98 nicks [0 ops, 0 halfops, 0 voices, 98 normal]
08:23 --- Channel #awk was synced in 110 seconds
12:22  ch077179: what's wrong wit  awk '{OFS="|";print $0}' to change the delimiter to | ?
12:23  ch077179: input=output...
12:23  pgas: you need to force awk to recalculate $0
12:24  pgas: awk 'BEGIN{OFS="|"}{$1=$1;print $0}'
12:25  pgas: the $1=$1 tricks awk into thinking that something as changed, otherwise, as an optimization it does nothing
12:27  ch077179: output is still unchanged
12:28  ch077179: this command is at the end of a pipeline, does that affect awk?
12:28  pgas: 4# echo foo bar | awk 'BEGIN{OFS="|"}{$1=$1;print $0}'
12:28  shbot: pgas: foo|bar
12:28  pgas: what do you try exactly?
12:29  ch077179:  awk -F" " '{print $4" " $5" " $6}' aix_system_accounts.txt | sort -k2 -u | awk 'BEGIN{OFS="|"}{$1=$1; print $0}'
12:30  pgas: well, that should work as demonstrated above
12:30  pgas: but you don't really need this:
12:31  ch077179: AIX 5.2 5200-10-07-0902 adm 4 4 <-- a line from aix_sys_acc.txt
12:32  pgas: 4# echo 'AIX 5.2 5200-10-07-0902 adm 4 4' | awk -F" " '{print $4" " $5" " $6} | sort -k2 -u | awk 'BEGIN{OFS="|"}{$1=$1;print $0}'
12:32  shbot: pgas: Missing terminating quote, bracket or keyword
12:32  ch077179: I want to extract the last 3 fields and sort by uid
12:32  pgas: 4# echo 'AIX 5.2 5200-10-07-0902 adm 4 4' | awk -F" " '{print $4" " $5" " $6}' | sort -k2 -u | awk 'BEGIN{OFS="|"}{$1=$1;print $0}'
12:32  shbot: pgas: adm|4|4
12:33  pgas: 4# echo 'AIX 5.2 5200-10-07-0902 adm 4 4' | awk -F" " -v OFS='|''{print $4,$5,$6}' | sort -t '|' -k2,2 -u 
12:33  shbot: pgas: Usage: awk [POSIX or GNU style options] -f progfile [--] file ...
12:33  shbot: pgas: Usage: awk [POSIX or GNU style options] [--] 'program' file ...
12:33  shbot: pgas: etc... ( http://pastebin.com/tRLNdF9Y )
12:33  pgas: 4# echo 'AIX 5.2 5200-10-07-0902 adm 4 4' | awk -F" " -v OFS='|' '{print $4,$5,$6}' | sort -t '|' -k2,2 -u 
12:33  shbot: pgas: adm|4|4
12:33  ch077179: I execute the exact same line, and I get whitespace separated output
12:33  pgas: hmm, maybe $1=$1 is not enough to trick your awk? what if you try nawk? or another awk?
12:34  pgas: (though see my second example too)
12:34  pgas: also if you don't need the output sorted you can remove the sort altogether
12:35  ch077179: I want to sort by uid, the second last column of the original input
12:35  pgas: ok
12:35  ch077179: your last command works
12:37  ch077179: ty pgas
12:45  pgas: you're welcom
12:45  pgas: e
13:05  ecraven: hello. how can i remove the last line of a file with awk?
13:10  karthee: ecraven: printf '%s\n' '$-1,$d' w | ed -s filename
13:11  pgas: with awk you would need to use a little buffer
13:12  pgas: awk 'NR>1{print p}{p=$0}'
13:12  karthee: ecraven:    sed -n '$!p' ald
13:13  pgas: sed '$d'
13:13  karthee: :-)
13:13  pgas: you can also use just $d with ed
13:13  karthee: pgas: yes you are correct..
13:19  ecraven: ah, thanks!
13:21  ecraven: another one, how can i insert <p> at the beginning of every paragraph, and </p> at the end?
13:21  ecraven: i can't get sed to work with \n\n :(
13:24  pgas: awk -v RS= '{print "<p>" $0 "</p>"}'
13:24  ecraven: thanks! RS is record separator?
13:25  pgas: yes, a null RS means RS='\n\n'
13:25  pgas: or even \n+  I don't rememeber, but regexp in RS is not portable
13:27  ecraven: does awk support an in-place editing switch? like -i in sed?
13:29  pgas: no
13:29  pgas: (note that sed doesn't really do in-place either, it replace the old file by a new one)
13:37  ecraven: is there an easy way to convert a string to lowercase but with all initial letters uppercase? as in emacs M-x upcase-initials-region
13:40  ecraven: sed 's/\([a-zA-Z]\)\([a-zA-Z0-9]*\)/\u\1\L\2/g'  ;)
13:42  pgas:  toUpper(substr(string,1,1)) toLower(substr(string,2))
13:43  pgas: 4# echo foOBar| awk '{print toUpper(substr($0,1,1)) toLower(substr($0,2))}' 
13:43  shbot: pgas: awk: (FILENAME=- FNR=1) fatal: function `toUpper' not defined
13:43  pgas: 4# echo foOBar| awk '{print toupper(substr($0,1,1)) tolower(substr($0,2))}' 
13:43  shbot: pgas: Foobar
13:55  ecraven: trying to make it into a function, is function upcaseInitials(str) { return (toupper(substr($0,1,1)) tolower(substr($0,2))) } correct?
13:56  ecraven: ah, not $0, str
15:37  a1fa: to awk or not to awk
15:38  a1fa: I have a silly request.. My data is not linear, but it is spread across several new lines
15:38  a1fa: what would be the best way to move that into csv?
15:42  pgas: to put everything on one line?
15:42  pgas: or to put every N lines on one line?
15:42  a1fa: http://pastebin.ca/1981759
15:42  a1fa: i was going to to use RS=""; FS="\n"
15:42  a1fa: and process it like that
15:43  pgas: I would use : paste -d \; -s
15:43  a1fa: paste -d \;  -s?
15:43  a1fa: que :)
15:44  pgas: 4# { echo foo; echo bar;}  | paste -d \; -s
15:44  shbot: pgas: foo;bar
15:44  pgas: paste is a comamnd
15:44  a1fa: i know
15:44  a1fa: but i am looking how that would work on grand scheme of things
15:45  pgas: so you want a awk solution?
15:45  a1fa: yes
15:45  a1fa: :)
15:45  a1fa: I <3 awk
15:45  pgas: do you mind the ; at the end of the line?
15:45  a1fa: no
15:45  a1fa: dont write it for me :)
15:45  a1fa: let me figure it  out
15:45  a1fa: no point of fishing 
15:45  a1fa: if i cant fish for myself -- right?
15:46  pgas: ah, then have a look at ORS
15:46  a1fa: i just wanted to see what the consensus was
15:46  a1fa: on using RS and FS
15:46  a1fa: i can do more intelligent things and split things
15:46  pgas: RS and FS are used to read the file, not to write it
15:47  pgas: RS="" split the file at blank lines
15:47  pgas: it doesn't mean "read the whole file"
15:47  pgas: in your case, I would keep the default RS and FS
15:48  a1fa: but you see how source: record is on newline
15:48  a1fa: and the field variables are on the next line
15:48  pgas: but you just need records, not fields
15:49  a1fa: ok
15:49  a1fa: let me check the paste command 
15:49  a1fa: right.. and there are mutliple records per section
15:49  pgas: a1fa: check ORS in the doc and see what you can do with it for your problem
15:50  a1fa: i am not worried about output as much as i am worried about having that data
15:50  a1fa: loaded into the code
15:51  pgas: ah ...
15:51  a1fa: check out my output
15:51  a1fa: i don't really care oabout "Soruce:"
15:52  a1fa: that is just a field name
15:52  a1fa: i need to grab the records within that fiewld
15:52  pgas: ok, so skeep it
15:52  pgas: *skip
15:52  a1fa: right
15:53  a1fa: so i am going to go with RS, and FS?
15:53  a1fa: hooah?
15:54  a1fa: so FS="Source:"
15:54  pgas: awk -v ORS=; '!/Source:/'
15:55  a1fa: but it also has to be on destination and service
15:55  a1fa: ;)
15:55  a1fa: so !/Source:|Destination:|Service:/
15:56  a1fa: and not so much with ORS
15:56  a1fa: because i can just print tha tout
15:57  pgas: sure  '{printf "%s%s",s,$0";s=";"}'
15:57  a1fa: right
15:57  a1fa: so FS=!/Source: ?
15:57  pgas: no quite right, I have a " too much 
15:58  pgas: play with FS if you want....
15:58  a1fa: it just seems easyer
15:58  a1fa: easier?
15:59  a1fa: does FS even take regex?
15:59  pgas: yes, if FS is more than one char then it 's a regexp
15:59  pgas: !/Source:  is not a regexp though, 
16:00  pgas: and you can't do var=/regexp/ , you need a string literal: var="regexp"
16:00  a1fa: FS =/Source:|Destination:|Service:/
16:04  a1fa: my record separators are blank new line
16:04  a1fa: so RS=\n
16:04  a1fa: or RS =""
16:05  a1fa: or if i want to be lazy, i can just replace Source: with :
16:05  a1fa: using a text editor
16:05  a1fa: but i'd like to learn so i dont have to do that
16:05  a1fa: that way my field sparator could be just :
16:06  a1fa: sure nuff.. 3.5.1 in the manua
16:06  a1fa: manual
16:10  pgas: RS="\n" is the default
16:12  a1fa: ok so RS=""
16:12  a1fa: for blank new line?
16:14  pgas: yes
16:15  a1fa: hm
16:15  a1fa: not working quiet right
16:16  a1fa: BEGIN { OFS ="," ; RS = "" ; FS ="(Sources|Destinations|Service)" ; }
16:17  a1fa: aw
16:17  a1fa: that will not work
16:17  a1fa: i get it
16:17  a1fa: i need to define field1 field2 and field3
16:17  pgas: {$1=$1;print}
16:17  pgas: you need to force awk to recompute $0 with eg $1=$1
16:17  pgas: then to print it
16:18  a1fa: ok. so is there a way to tell awk FIELD1=
16:18  pgas: $1=
16:19  a1fa: no no :) 
16:19  a1fa: i mean is there way to tell awk 
16:19  pgas: tell awk what?
16:19  a1fa:  nvm
16:20  a1fa: i just need to go in and replace Sources
16:20  a1fa: destinations
16:20  a1fa: and services with :
16:20  a1fa: and i will be golden
16:21  a1fa: however this should have worked
16:21  a1fa: FS ="(Sources|Destinations|Service)" ; 
16:23  pgas: this doesn't do anything per se
16:24  a1fa: ok another idea
16:33  a1fa: lets think about this
16:34  a1fa: FS="(Sources|Destinations|Service)"
16:34  a1fa: this should match field separators, so $1 will be anything under Source
16:34  a1fa: or; it wont
16:35  a1fa: fail
16:36  a1fa: i have it
16:36  a1fa: RS=""; FS="\n"
16:36  a1fa: score
16:47  steve___: pgas: He wanted you to teach him to fish; instead he showed you how to tie knots in the line  ;)
16:47  a1fa: i got it figured out
16:47  a1fa: all i have to do is use if
16:47  a1fa: statemens per record
16:53  a1fa: can you change a record separator mid line?
16:54  waldner: no, but you can always use split()
16:54  ch077179_: how can I list the number of lines per number of records in a line?
16:55  a1fa: i am going to next ;)
16:55  waldner: ch077179_: what does that mean?
16:55  waldner: normally, a line is a record, if you don't change RS
16:55  ch077179_: unfortunately I have a file where some lines do not have the same number of records as the rest
16:55  ch077179_: I want to know how big that polluted part is
16:56  waldner: you mean fields
16:56  ch077179_: ah forgive me, yes fields
16:56  waldner: you want to print how many fields each line has?
16:56  ch077179_: not each, I just want to know the number of lines per realization of number of fields
16:57  waldner: awk '{n[NF]++}END{for(i in n)print i, n[i]}'
16:58  ch077179_: hm.. I think it is looking for " " as FS, but I have FS":"
16:59  a1fa: wow 
16:59  a1fa: this is nasty as fuck
16:59  a1fa: but i got it to work
17:02  a1fa: http://pastebin.ca/1981861
17:03  a1fa: very dirty
17:03  a1fa: but very usable
17:05  a1fa: what do you say
17:40  a1fa: pgas: thanks
17:40  a1fa: sometimes simple solutions are the easiest
17:40  a1fa: i was way over complicating things
--- Log closed Fri Nov 05 12:52:00 2010
